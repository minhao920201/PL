{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb01c3db",
   "metadata": {},
   "source": [
    "# 爬取網站 : [IT邦幫忙](https://ithelp.ithome.com.tw/)\n",
    "## 抓取內容 : 文章的標題、標籤、詢問日期、瀏覽次數\n",
    "### P.S. 為了避免出現不必要的格式錯誤，將標題、標籤利用REGEX替換特定符號，替換前及替換後如下\n",
    "### ( (換行符號(\\n) -> EOF)　,　(Tab(\\t) ->     (四個空白))　,　(, -> ，) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6063a84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as req #引入urllib模組中函式名稱為request的函式為req\n",
    "import bs4 #引入bs4模組\n",
    "import re\n",
    "#定義函式getData，用以取得每一頁所有標題、標籤及內文。參數為網址\n",
    "def getData(url,count,pages):\n",
    "\n",
    "    #建立一個Request物件，附加Request Headers的資訊\n",
    "    request = req.Request(url,headers = {\n",
    "        \"User-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.0.0 Safari/537.36\"\n",
    "    })\n",
    "    \n",
    "    #打開request\n",
    "    with req.urlopen(request) as response:\n",
    "        data = response.read().decode(\"utf-8\")\n",
    "\n",
    "    root = bs4.BeautifulSoup(data,\"html.parser\") #讓BeautifulSoup解析HTML格式文件\n",
    "    all_titles = root.find_all(\"h3\",class_=\"qa-list__title\") #以列表形式找出所有class_=title的h3標籤\n",
    "\n",
    "\n",
    "    #開啟finalproject.txt並用a模式保留原本資料並將新的資料寫入\n",
    "    with open(\"csvpy.csv\",mode = \"a\",encoding = \"big5\") as ftext:\n",
    "        #此迴圈會找出該頁所有標題、標籤及內文\n",
    "        for title in all_titles:\n",
    "            url2 = title.a[\"href\"] #將內文的網址存到url2裡\n",
    "\n",
    "            #建立一個Request物件，附加Request Headers的資訊\n",
    "            request2 = req.Request(url2,headers = {\n",
    "                \"User-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.0.0 Safari/537.36\"\n",
    "            })\n",
    "\n",
    "            #打開request2\n",
    "            with req.urlopen(request2) as response2:\n",
    "                data2 = response2.read().decode(\"utf-8\")\n",
    "            \n",
    "            root2 = bs4.BeautifulSoup(data2,\"html.parser\") #讓BeautifulSoup解析HTML格式文件\n",
    "            tags = root2.find(\"div\",class_=\"qa-header__tagGroup\") #以列表形式找出所有 class_=qa-header__tagGroup 的 div 標籤\n",
    "            time_and_view = root2.find(\"div\",class_=\"qa-header__info\").text.split() #以列表形式找出所有 class_=qa-header__info 的 div 標籤\n",
    "            \n",
    "            #利用regex將會影響CSV的符號做替換\n",
    "            title.a.string = re.sub(r\",\",\"，\",title.a.string)\n",
    "\n",
    "            set_of_tags = set(tags.text.split(\"\\n\")) #利用集合將重複出現的標籤強制讓它出現一次\n",
    "            #將集合內的資料重新裝回list內\n",
    "            list_of_tags = []\n",
    "            for i in set_of_tags:\n",
    "                list_of_tags.append(i)\n",
    "            \n",
    "            #將標籤、詢問日期、瀏覽次數及內文寫進CSV檔\n",
    "            for tag in list_of_tags[1:]:\n",
    "                tag = re.sub(r\",\",\"，\",tag)\n",
    "                ftext.write(title.a.string+\",\")\n",
    "                ftext.write(tag + \",\")\n",
    "                ftext.write(time_and_view[1]+\",\")\n",
    "                ftext.write(time_and_view[-2]+\",\")\n",
    "                ftext.write(contents+\"\\n\")\n",
    "                print(\"標題 : \"+title.a.string)\n",
    "                print(\"標籤 : \"+tag)\n",
    "                print(\"詢問日期 : \"+time_and_view[1])\n",
    "                print(\"瀏覽次數 : \"+time_and_view[-2])\n",
    "                print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "    #抓取下一頁的連結\n",
    "    nextLink = root.find(\"a\",string=\"下一頁\") #找到內文是 下一頁 的標籤a\n",
    "    return nextLink[\"href\"] #回傳下一頁的網址\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a32492",
   "metadata": {},
   "source": [
    "# 主程式\n",
    "### 要求使用者輸入想抓取多少頁數的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d548a0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter how many pages you want to crawl:1\n",
      "標題 : 爬蟲問題\n",
      "標籤 : big5\n",
      "詢問日期 : 2022-11-02\n",
      "瀏覽次數 : 25\n",
      "內文 : \n",
      "我原本想用爬蟲把IT邦邦忙網站中的文章\"標題\"，\"標籤\"，\"詢問時間\"，\"瀏覽次數\"，還有\"問題敘述\"抓下來用csv檔儲存，禮拜一用的時候好好的，結果今天用就突然掛掉。\n",
      "我看了一下error好像是有人文章裡的\"問題敘述\"格式不符合csv檔用的文字編碼big5\n",
      "跑出的error長這樣 :\n",
      "UnicodeEncodeError: 'big5' codec can't encode character '\\u6ca1' in position 3244: illegal multibyte sequence\n",
      "想請問這段error是什麼意思?要如何解決?\n",
      "更:我自己這篇文章的東西有抓下來，到下面那篇文章的\"問題敘述\"就抓不下來了，應該是那篇文章的內容有影響到\n",
      "contents = root2.find(\"div\",class_=\"markdown__style\").text #找出內文\n",
      "\n",
      "這段是我用來抓\"問題敘述\"的程式\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "標題 : 爬蟲問題\n",
      "標籤 : csv\n",
      "詢問日期 : 2022-11-02\n",
      "瀏覽次數 : 25\n",
      "內文 : \n",
      "我原本想用爬蟲把IT邦邦忙網站中的文章\"標題\"，\"標籤\"，\"詢問時間\"，\"瀏覽次數\"，還有\"問題敘述\"抓下來用csv檔儲存，禮拜一用的時候好好的，結果今天用就突然掛掉。\n",
      "我看了一下error好像是有人文章裡的\"問題敘述\"格式不符合csv檔用的文字編碼big5\n",
      "跑出的error長這樣 :\n",
      "UnicodeEncodeError: 'big5' codec can't encode character '\\u6ca1' in position 3244: illegal multibyte sequence\n",
      "想請問這段error是什麼意思?要如何解決?\n",
      "更:我自己這篇文章的東西有抓下來，到下面那篇文章的\"問題敘述\"就抓不下來了，應該是那篇文章的內容有影響到\n",
      "contents = root2.find(\"div\",class_=\"markdown__style\").text #找出內文\n",
      "\n",
      "這段是我用來抓\"問題敘述\"的程式\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "標題 : 爬蟲問題\n",
      "標籤 : 文字編碼\n",
      "詢問日期 : 2022-11-02\n",
      "瀏覽次數 : 25\n",
      "內文 : \n",
      "我原本想用爬蟲把IT邦邦忙網站中的文章\"標題\"，\"標籤\"，\"詢問時間\"，\"瀏覽次數\"，還有\"問題敘述\"抓下來用csv檔儲存，禮拜一用的時候好好的，結果今天用就突然掛掉。\n",
      "我看了一下error好像是有人文章裡的\"問題敘述\"格式不符合csv檔用的文字編碼big5\n",
      "跑出的error長這樣 :\n",
      "UnicodeEncodeError: 'big5' codec can't encode character '\\u6ca1' in position 3244: illegal multibyte sequence\n",
      "想請問這段error是什麼意思?要如何解決?\n",
      "更:我自己這篇文章的東西有抓下來，到下面那篇文章的\"問題敘述\"就抓不下來了，應該是那篇文章的內容有影響到\n",
      "contents = root2.find(\"div\",class_=\"markdown__style\").text #找出內文\n",
      "\n",
      "這段是我用來抓\"問題敘述\"的程式\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "標題 : 爬蟲問題\n",
      "標籤 : 爬蟲\n",
      "詢問日期 : 2022-11-02\n",
      "瀏覽次數 : 25\n",
      "內文 : \n",
      "我原本想用爬蟲把IT邦邦忙網站中的文章\"標題\"，\"標籤\"，\"詢問時間\"，\"瀏覽次數\"，還有\"問題敘述\"抓下來用csv檔儲存，禮拜一用的時候好好的，結果今天用就突然掛掉。\n",
      "我看了一下error好像是有人文章裡的\"問題敘述\"格式不符合csv檔用的文字編碼big5\n",
      "跑出的error長這樣 :\n",
      "UnicodeEncodeError: 'big5' codec can't encode character '\\u6ca1' in position 3244: illegal multibyte sequence\n",
      "想請問這段error是什麼意思?要如何解決?\n",
      "更:我自己這篇文章的東西有抓下來，到下面那篇文章的\"問題敘述\"就抓不下來了，應該是那篇文章的內容有影響到\n",
      "contents = root2.find(\"div\",class_=\"markdown__style\").text #找出內文\n",
      "\n",
      "這段是我用來抓\"問題敘述\"的程式\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "標題 : 爬蟲問題\n",
      "標籤 : error\n",
      "詢問日期 : 2022-11-02\n",
      "瀏覽次數 : 25\n",
      "內文 : \n",
      "我原本想用爬蟲把IT邦邦忙網站中的文章\"標題\"，\"標籤\"，\"詢問時間\"，\"瀏覽次數\"，還有\"問題敘述\"抓下來用csv檔儲存，禮拜一用的時候好好的，結果今天用就突然掛掉。\n",
      "我看了一下error好像是有人文章裡的\"問題敘述\"格式不符合csv檔用的文字編碼big5\n",
      "跑出的error長這樣 :\n",
      "UnicodeEncodeError: 'big5' codec can't encode character '\\u6ca1' in position 3244: illegal multibyte sequence\n",
      "想請問這段error是什麼意思?要如何解決?\n",
      "更:我自己這篇文章的東西有抓下來，到下面那篇文章的\"問題敘述\"就抓不下來了，應該是那篇文章的內容有影響到\n",
      "contents = root2.find(\"div\",class_=\"markdown__style\").text #找出內文\n",
      "\n",
      "這段是我用來抓\"問題敘述\"的程式\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'big5' codec can't encode character '\\u6ca1' in position 3156: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#重複抓取每頁資料\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m count\u001b[38;5;241m<\u001b[39mpages:\n\u001b[1;32m---> 11\u001b[0m     pageURL \u001b[38;5;241m=\u001b[39m \u001b[43mgetData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpageURL\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpages\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#將 return 回來的網址覆蓋到pageURL上，以便重複利用\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mgetData\u001b[1;34m(url, count, pages)\u001b[0m\n\u001b[0;32m     54\u001b[0m ftext\u001b[38;5;241m.\u001b[39mwrite(time_and_view[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m ftext\u001b[38;5;241m.\u001b[39mwrite(time_and_view[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m \u001b[43mftext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m標題 : \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mtitle\u001b[38;5;241m.\u001b[39ma\u001b[38;5;241m.\u001b[39mstring)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m標籤 : \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mtag)\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'big5' codec can't encode character '\\u6ca1' in position 3156: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "#將每列代表的意義寫入CSV檔\n",
    "with open(\"csvpy.csv\",mode = \"a\",encoding = \"big5\") as ftext:\n",
    "    ftext.write(\"標題,標籤,詢問時間,瀏覽次數,內文\\n\")\n",
    "\n",
    "pageURL = \"https://ithelp.ithome.com.tw/\" #將起始網頁的網址存到pageURL裡\n",
    "count = 0 #count用來表示想抓取幾頁\n",
    "pages = int(input(\"Please enter how many pages you want to crawl:\")) #輸入要抓取幾頁資料\n",
    "\n",
    "#重複抓取每頁資料\n",
    "while count<pages:\n",
    "    pageURL = getData(pageURL,count,pages) #將 return 回來的網址覆蓋到pageURL上，以便重複利用\n",
    "    count += 1 #執行完一次後增加1，以確保能抓到預期的頁數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b5ac16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
